{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "8c23eab2-4c21-423c-92f8-407e7ded4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx import stock\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2df223cb-1b47-4895-92b6-45c44bd4caeb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filtering_company(company):\n",
    "    if pd.isna(company):\n",
    "        return np.nan\n",
    "    \n",
    "    original = company\n",
    "    \n",
    "    # 긴 것 -> 작은 것(ex> 주식회사 -> 주)\n",
    "    company = company.replace('(농업회사법인유한회사)', '')\n",
    "    company = company.replace('의료법인)', '')\n",
    "    company = company.replace('농업회사법인', '')\n",
    "    company = company.replace('가부시키가이샤', '')\n",
    "    company = company.replace('카부시키카이샤', '')\n",
    "    company = company.replace('(유한회사)', '')\n",
    "    company = company.replace('주식회사', '')\n",
    "    company = company.replace('㈜', '')\n",
    "    company = company.replace('(주)', '')\n",
    "    company = company.replace('（주）', '')\n",
    "    company = company.replace('( 주 )', '')\n",
    "    company = company.replace('( 주)', '')\n",
    "    company = company.replace('(주 )', '')\n",
    "    company = company.replace('주)', '')\n",
    "    company = company.replace('주 )', '')\n",
    "    company = company.replace('(유)', '')\n",
    "    company = company.replace('유)', '')\n",
    "    company = company.replace('우)', '')\n",
    "    company = company.replace('(사)', '')\n",
    "    company = company.replace('사)', '')\n",
    "    company = company.replace('  ', ' ') # 신정보개발주식회사 ~~\n",
    "    company = company.split('|')[0] # 상위 -> 하위\n",
    "\n",
    "    try:\n",
    "        \n",
    "        length = len(company)\n",
    "        index = set(range(length))\n",
    "\n",
    "        pairs1 = list()\n",
    "        stack = list()\n",
    "        for i in range(length):\n",
    "            if company[i] == '(':\n",
    "                stack.append(i)\n",
    "            elif company[i] == ')':\n",
    "                if stack:\n",
    "                    pairs1.append((stack.pop(), i))\n",
    "                else:\n",
    "                    if pairs1:\n",
    "                        pairs1.append((pairs1.pop()[0], i))\n",
    "                    else:\n",
    "                        pairs1.append((i, i))\n",
    "        \n",
    "        if stack:\n",
    "            pairs1.append((stack[0], length-1))\n",
    "        \n",
    "        pairs2 = list()\n",
    "        stack = list()\n",
    "        for i in range(length):\n",
    "            if company[i] == '[':\n",
    "                stack.append(i)\n",
    "            elif company[i] == ']':\n",
    "                if stack:\n",
    "                    pairs2.append((stack.pop(), i))\n",
    "                else:\n",
    "                    if pairs2:\n",
    "                        pairs2.append((pairs2.pop()[0], i))\n",
    "                    else:\n",
    "                        pairs2.append((i, i))\n",
    "                        \n",
    "        if stack:\n",
    "            pairs2.append((stack[0], length-1))\n",
    "            \n",
    "        for start, end in pairs1 + pairs2:\n",
    "            index -= set(range(start, end+1))\n",
    "\n",
    "        index = list(index)\n",
    "        index.sort()\n",
    "        company = ''.join([company[idx] for idx in index])\n",
    "    \n",
    "        company = company.strip()\n",
    "    \n",
    "    except:\n",
    "        print(original, '--->', company)\n",
    "        \n",
    "    return company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92944ffd-2f10-45a8-8e50-533eeca8e867",
   "metadata": {},
   "source": [
    "# data collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbe70f-c340-4ac1-9f6f-55ff542d4e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebe2dc-3dd5-482f-b1a3-178e895e58ca",
   "metadata": {},
   "source": [
    "- KOSPI / KOSDAQ 연 종가 수익률 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff63c10b-24d1-4f2d-a850-07d4cd554929",
   "metadata": {},
   "outputs": [],
   "source": [
    "kospi_y = stock.get_index_ohlcv(\"20020101\", \"20221231\", \"1001\", 'y')\n",
    "kosdaq_y = stock.get_index_ohlcv(\"20020101\", \"20221231\", \"2001\", 'y')\n",
    "\n",
    "kospi_y['연 수익률'] = (kospi_y['종가'] - kospi_y['종가'].shift(1)) / kospi_y['종가'].shift(1)\n",
    "kospi_er = np.mean(kospi_y['연 수익률']) * 100\n",
    "kosdaq_y['연 수익률'] = (kosdaq_y['종가'] - kosdaq_y['종가'].shift(1)) / kosdaq_y['종가'].shift(1)\n",
    "kosdaq_er = np.mean(kosdaq_y['연 수익률']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2964d18d-8005-4472-a61d-ac736e13adcf",
   "metadata": {},
   "source": [
    "- KOSPI / KOSDAQ 월 종가 수익률 (20개년)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff49e02-5b85-4761-842d-686cb7535838",
   "metadata": {},
   "outputs": [],
   "source": [
    "kospi_m = stock.get_index_ohlcv(\"20120101\", \"20221231\", \"1001\", 'm')\n",
    "kosdaq_m = stock.get_index_ohlcv(\"20120101\", \"20221231\", \"2001\", 'm')\n",
    "\n",
    "kospi_m = kospi_m.reset_index(drop=False)[['날짜', '종가']]\n",
    "kosdaq_m = kosdaq_m.reset_index(drop=False)[['날짜', '종가']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572f61a-8b8d-48f1-b05b-10d6ef094514",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_tickers = stock.get_market_ticker_list(\"20221231\", market=\"KOSPI\")\n",
    "daq_tickers = stock.get_market_ticker_list(\"20221231\", market=\"KOSDAQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5eabd-19d9-4bd2-8e93-3989096d2490",
   "metadata": {},
   "source": [
    "- 상장기업 월 종가 수익률 (20개년)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb66c3d5-9ec7-4958-9c61-c8c320f8e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./data/all_data_2022.csv')\n",
    "dart_corp = all_df[all_df['상장분류']==True]\n",
    "dart_corp_m = dart_corp[['회사명', '종목코드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7475b6-ec2f-46c0-b450-cf52fdb55e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "error_idx = []\n",
    "df_list = []\n",
    "\n",
    "for corp_code in tqdm.tqdm(dart_corp['종목코드']):\n",
    "    try:\n",
    "        corp_code_s = str(int(corp_code)).zfill(6)\n",
    "        result = stock.get_market_ohlcv(\"20120101\", \"20221231\", corp_code_s, 'm')['종가'].to_frame().reset_index()\n",
    "        result['종목코드'] = corp_code\n",
    "        # pd.merge(dart_corp_m, result, on='종목코드')\n",
    "        df_list.append(result)\n",
    "    except (KeyError, IndexError):\n",
    "        print('error', corp_code)\n",
    "        error_idx.append(corp_code)\n",
    "with open(\"./data/list_result.pkl\",\"wb\") as f:\n",
    "    pickle.dump(df_list, f)        \n",
    "# 로컬에서 돌림\n",
    "\n",
    "with open(\"./data/list_result.pkl\",\"rb\") as f:\n",
    "    list_ex_load = pickle.load(f)\n",
    "merged_df = pd.concat(list_ex_load, ignore_index=True)\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "dart_m = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca9c83-2142-4799-bbb9-223faa9aa1de",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c47183-28f0-46df-be4b-cf3cab89ea31",
   "metadata": {},
   "source": [
    "### Regression\n",
    "- weight 값을 상장기업 levered beta 로 산정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3dbf2-b115-46d3-a228-1d6f3c0aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_m['시장'] = ''\n",
    "dart_m.loc[dart_m['종목코드'].apply(lambda x: str(int(x)).zfill(6) in pi_tickers) == True, '시장'] = 'KOSPI'\n",
    "dart_m.loc[dart_m['종목코드'].apply(lambda x: str(int(x)).zfill(6) in daq_tickers) == True, '시장'] = 'KOSDAQ'\n",
    "dart_m.loc[dart_m['종목코드'] == 344860, '시장'] = 'KOSDAQ'\n",
    "\n",
    "kosdaq_m['시장'] = 'KOSDAQ'\n",
    "kospi_m['시장'] = 'KOSPI'\n",
    "kosdaq_m['er'] = kosdaq_er\n",
    "kospi_m['er'] = kospi_er\n",
    "\n",
    "dart_m = pd.merge(dart_m, kosdaq_m, on=['날짜', '시장'], how='left')\n",
    "dart_m = pd.merge(dart_m, kospi_m, on=['날짜', '시장'], how='left')\n",
    "dart_m['시장종가'] = dart_m['종가_y'].fillna(dart_m['종가'])\n",
    "dart_m['시장ER'] = dart_m['er_y'].fillna(dart_m['er_x'])\n",
    "dart_m = dart_m.drop(columns=['종가_y', '종가'], axis=1)\n",
    "dart_m = dart_m.drop(columns=['er_y', 'er_x'], axis=1)\n",
    "dart_m = dart_m.rename(columns={'종가_x':'종목종가'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647713a-1787-47ae-8434-165376902f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def get_weight(group):\n",
    "    x = group['시장종가'].values.reshape(-1, 1)\n",
    "    y = group['종목종가'].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    return model.coef_[0]\n",
    "temp = dart_m.groupby(['종목코드']).apply(get_weight).reset_index()\n",
    "temp.columns = ['종목코드', 'levered_b']\n",
    "\n",
    "temp_filtered = temp[(temp['levered_b'] < 2) & (temp['levered_b'] > -2)]\n",
    "temp_filtered = temp_filtered[temp_filtered['levered_b'] != 0]\n",
    "\n",
    "dart_m_er = dart_m[['종목코드', '시장ER']].drop_duplicates()\n",
    "temp_filtered = pd.merge(temp_filtered, dart_m_er, on='종목코드')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc454da-e4d9-424d-89f6-c979b2a725d7",
   "metadata": {},
   "source": [
    "## Rule base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c82dc-21ba-489d-95a0-28ab1026dfb4",
   "metadata": {},
   "source": [
    "### 상장기업 unlevered beta\n",
    "- 상장기업 unlevered beta 구하기 (rule base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a121aaa-0904-4739-8671-c4d0bd1ef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('./all_data_2022.csv')\n",
    "dart_corp = all_df[all_df['상장분류']==True]\n",
    "dart_corp = dart_corp[['회사명', '부채총액', '자본총계', '당기순이익', '종목코드']]\n",
    "dart_corp = pd.merge(dart_corp, temp_filtered, on='종목코드')\n",
    "\n",
    "conditions = [\n",
    "    (dart_corp['당기순이익'] <= 2e+8),\n",
    "    (dart_corp['당기순이익'] > 2e+8) & (dart_corp['당기순이익'] <= 2e+10),\n",
    "    (dart_corp['당기순이익'] > 2e+10) & (dart_corp['당기순이익'] <= 3e+11),\n",
    "    (dart_corp['당기순이익'] > 3e+11)\n",
    "]\n",
    "values = [0.09, 0.19, 0.21, 0.24]\n",
    "\n",
    "dart_corp['법인세율'] = np.select(conditions, values, default='Other')\n",
    "dart_corp = dart_corp.drop_duplicates('회사명').reset_index(drop=True)\n",
    "dart_corp['unlevered_b'] = dart_corp['levered_b'] * (1 + (1-dart_corp['법인세율'].apply(float)) * dart_corp['부채총액'] / dart_corp['자본총계'])\n",
    "\n",
    "temp_filtered = dart_corp[(dart_corp['levered_b'] < 2) & (dart_corp['levered_b'] > -2)]\n",
    "temp_filtered = temp_filtered[temp_filtered['levered_b'] != 0]\n",
    "temp_filtered[['회사명', '종목코드', 'unlevered_b', 'levered_b', '시장ER']].to_csv('./beta_상.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed4185-f025-482d-b18b-e32272f731e8",
   "metadata": {},
   "source": [
    "### 비상장기업 levered beta \n",
    "- ordered corp 기반으로 unlevered beta 평균 구한 뒤 비상장기업 levered beta 구하기 (rule base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590aa94-b729-439d-b28c-b55b66fd1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_df = pd.read_table('./company_mapping (1).tsv')\n",
    "mapped_df = mapped_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "df = mapped_df[['회사명_비상장', '회사명_상장']]\n",
    "df['회사명_상장'] = df['회사명_상장'].apply(lambda x : [data.strip()[1:-1] for data in x[1:-1].split(',')])\n",
    "df = df.explode('회사명_상장').sort_values('회사명_비상장')\n",
    "\n",
    "df['회사명_상장'] = df['회사명_상장'].apply(filtering_company)\n",
    "df['회사명_비상장'] = df['회사명_비상장'].apply(filtering_company)\n",
    "\n",
    "smes_corp = all_df[all_df['상장분류']==False]\n",
    "smes_corp = smes_corp[['회사명', '부채총액', '자본총계', '당기순이익']]\n",
    "\n",
    "conditions = [\n",
    "    (smes_corp['당기순이익'] <= 2e+8),\n",
    "    (smes_corp['당기순이익'] > 2e+8) & (smes_corp['당기순이익'] <= 2e+10),\n",
    "    (smes_corp['당기순이익'] > 2e+10) & (smes_corp['당기순이익'] <= 3e+11),\n",
    "    (smes_corp['당기순이익'] > 3e+11)\n",
    "]\n",
    "values = [0.09, 0.19, 0.21, 0.24]\n",
    "\n",
    "smes_corp['법인세율'] = np.select(conditions, values, default='Other')\n",
    "t = pd.read_csv('./beta_상.csv')[['회사명', 'unlevered_b', 'levered_b', '시장ER']]\n",
    "t = t.rename(columns={'회사명':'회사명_상장', 'unlevered_b':'상장_unlevered_b', 'levered_b':'상장_levered_b', '시장ER':'상장_시장ER'})\n",
    "\n",
    "df = pd.merge(df, t, on='회사명_상장')\n",
    "df['m_상장_unlevered_b'] = df.groupby('회사명_비상장')['상장_unlevered_b'].transform('mean')\n",
    "df = df.drop_duplicates(['회사명_비상장'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf27795-7c37-4775-b596-8c5da6053e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smes_corp = pd.merge(smes_corp, df, left_on = '회사명', right_on = '회사명_비상장')\n",
    "smes_corp = smes_corp.drop_duplicates('회사명')\n",
    "smes_corp = smes_corp.drop(['회사명_비상장', '회사명_상장'], axis=1)\n",
    "smes_corp = smes_corp.reset_index(drop=True)\n",
    "smes_corp['비상장_levered_b'] = smes_corp['m_상장_unlevered_b'] * (1+(1-smes_corp['법인세율'].apply(float)) * smes_corp['부채총액'] / smes_corp['자본총계'])\n",
    "smes_corp[['회사명', '상장_levered_b', '비상장_levered_b']].to_csv('./beta_비.csv', index=False)\n",
    "smes_corp['CAPM'] = 3.5 + smes_corp['비상장_levered_b'] * (smes_corp['상장_시장ER'] - 3.5)\n",
    "\n",
    "def remove_outliers_iqr(df, column, k=1.5):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - k * IQR\n",
    "    upper_bound = Q3 + k * IQR\n",
    "    return df[((df[column] >= lower_bound) & (df[column] <= upper_bound))]\n",
    "\n",
    "# IQR 이상치 제거 적용\n",
    "smes_corp_f = remove_outliers_iqr(smes_corp, 'CAPM')\n",
    "smes_corp_f.to_csv('./data/smes_capm_filtered_iqr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed2ce87-d5d3-4c9a-9a71-ebfae9b7194c",
   "metadata": {},
   "source": [
    "# data preprocessing\n",
    "- latest year = 2022 & 3개년치 값을 모두 가지고 있는 비상장 기업의 데이터 이용하여, 추후 3개년 inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e3b97",
   "metadata": {},
   "source": [
    "<p>상장</p>\n",
    "\n",
    "- 상장기업 4개년치에서 (3개년 : x, 1개년 : y) 로 잡은 뒤 학습\n",
    "- model train input : 3개년 feature 8개 / output : 1개년 feature 8개\n",
    "\n",
    "<p>비상장</p>\n",
    "\n",
    "- model test input : 3개년 feature 8개 / output : 1개년 feature 8개\n",
    "- 이를 3개 반복학습하여 3개년 feature 8개 추가 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cd97b",
   "metadata": {},
   "source": [
    "### smes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "id": "c3b0161e-b972-4a08-b779-fdba9481e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/companies_info.json') as f:\n",
    "    js = json.loads(f.read())\n",
    "smes_company = pd.DataFrame(js).transpose()\n",
    "smes_company = smes_company.reset_index().rename(columns={'index':'회사명'})\n",
    "smes_company = smes_company.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "id": "aafa22f8-6994-4852-be5e-5507216eaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_columns = ['회사명', 'year', '부채총계', '자본총계', '매출액', '당기순이익', '영업이익', '현금및현금성자산', '감가상각비']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "id": "4315904a-c224-43da-ba4c-eb56f1ad7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "smes_company = smes_company.rename(columns={'liab':'부채총계', 'cash':'현금및현금성자산', 'equi':'자본총계', 'reve':'매출액', 'oper':'영업이익', 'depr':'감가상각비', 'neti':'당기순이익'})\n",
    "\n",
    "fs = list(smes_company.columns)\n",
    "fs = fs[4:]\n",
    "smes_company = smes_company.explode(fs)\n",
    "\n",
    "smes_company['year'] = smes_company['latest_year'].apply(int) - smes_company.groupby('회사명').cumcount()\n",
    "smes_company = smes_company.drop(['sector', 'product'], axis=1).reset_index(drop=True)\n",
    "smes_company['회사명'] = smes_company['회사명'].apply(filtering_company)\n",
    "smes_company = smes_company.reindex(columns=fixed_columns)\n",
    "\n",
    "filtering = ['부채총계', '현금및현금성자산', '자본총계', '매출액', '영업이익', '당기순이익']\n",
    "smes_company = smes_company[(smes_company[filtering] != '0').all(axis=1)]\n",
    "smes_company = smes_company[(smes_company[filtering] != '').all(axis=1)]\n",
    "\n",
    "idx = list(smes_company.columns)\n",
    "idx = idx[2:]\n",
    "for i in idx:\n",
    "    smes_company[i] = smes_company[i].str.replace(',','').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1094e77-53bd-4ac7-9715-4be5f3f2ce96",
   "metadata": {},
   "source": [
    "column 추가 : 순부채, EBITDA, 기업총가치, EBITDA배율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "id": "8af798a9-e32b-46b5-8157-9219690ee86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smes_company[f'순부채'] = smes_company[f'부채총계'] - smes_company[f'현금및현금성자산']\n",
    "smes_company[f'EBITDA'] = smes_company[f'영업이익'] + smes_company[f'감가상각비']\n",
    "smes_company[f'기업 가치'] = smes_company[f'자본총계'] + smes_company[f'순부채']\n",
    "smes_company[f'EBITDA배율'] = smes_company[f'기업 가치'] / smes_company[f'EBITDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "id": "658de8f9-0ccc-46ca-8076-a8dcd79a793e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['부채총계', '자본총계', '매출액', '당기순이익', '영업이익', '현금및현금성자산', '감가상각비']\n",
    "def calculate_growth_rate(group):\n",
    "    for c in columns:\n",
    "        group[f'r_{c}'] = (group[c] - group[c].shift(1)) / group[c].shift(1)\n",
    "    return group\n",
    "smes_company_r = smes_company.groupby('회사명').apply(calculate_growth_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "id": "09184d7e-52ba-41c9-bb96-305c6c3de51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smes_company_r = smes_company_r.reset_index(drop=True)\n",
    "smes_company_r['r_감가상각비'] = smes_company_r['r_감가상각비'].fillna(0)\n",
    "smes_company_r = smes_company_r.dropna()\n",
    "smes_company_r = smes_company_r.drop(columns=columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "id": "63d01322-e96f-489a-abb4-268f1324a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smes_company_r = smes_company_r.drop(['순부채', 'EBITDA', '기업 가치'], axis=1)\n",
    "smes_company_r = smes_company_r.sort_values(['회사명', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237069f7-7c46-401f-8c69-eb4fa45cf435",
   "metadata": {},
   "source": [
    "### dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "id": "687e0060-49ab-4186-8ac6-c1235ca965a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18853/3410894558.py:1: DtypeWarning: Columns (17,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dart = pd.read_csv('../data/final_df.csv')\n"
     ]
    }
   ],
   "source": [
    "dart = pd.read_csv('../data/final_df.csv')\n",
    "dart = dart[['회사명', '부채총계', '자본총계', '매출액', '당기순이익', '영업이익', '현금및현금성자산', '감가상각비', 'year', 'report_code', '법인유형']]\n",
    "dart['감가상각비'].fillna(0, inplace=True)\n",
    "dart = dart.dropna()\n",
    "dart[f'순부채'] = dart[f'부채총계'] - dart[f'현금및현금성자산']\n",
    "dart[f'EBITDA'] = dart[f'영업이익'] + dart[f'감가상각비']\n",
    "\n",
    "def check_years(group):\n",
    "    return len(group['year'].unique()) >=4 and len(group['report_code']) >= 4\n",
    "f_dart = dart.groupby('회사명').filter(check_years).reset_index(drop=True)\n",
    "\n",
    "f_dart = f_dart.drop_duplicates(subset=['회사명', 'year', 'report_code', '법인유형'], keep='last')\n",
    "f_dart_s = f_dart.sort_values(by=['회사명','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "id": "974e6408-abd5-4094-b0f8-2ed49bb5fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dart_s4 = f_dart_s[f_dart_s['report_code'] == 11011].groupby('회사명').filter(lambda x:len(x)==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "id": "96f46f62-8b70-419f-8b84-2fe63ebb8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dart_s5 = f_dart_s[f_dart_s['report_code'] == 11013].groupby('회사명').filter(lambda x:len(x)==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "id": "c4573822-7ffd-497b-91ff-deb1d32f3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_columns = ['부채총계', '자본총계', '매출액', '당기순이익', '영업이익', '현금및현금성자산','감가상각비', '순부채', 'EBITDA']\n",
    "fixed_columns_r = ['회사명', 'year', 'r_부채총계', 'r_자본총계', 'r_매출액', 'r_당기순이익', 'r_영업이익', 'r_현금및현금성자산', 'r_감가상각비']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "1999a92b-a5b1-402f-8131-7ad0e3e84696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_growth_rate(group):\n",
    "    for c in fixed_columns:\n",
    "        group[f'r_{c}'] = (group[c] - group[c].shift(1)) / group[c].shift(1)\n",
    "    return group\n",
    "temp = f_dart_s4.groupby('회사명').apply(calculate_growth_rate)\n",
    "# temp = f_dart_s5.groupby('회사명').apply(calculate_growth_rate)\n",
    "temp = temp.reset_index(drop=True)\n",
    "temp['r_감가상각비'] = temp['r_감가상각비'].fillna(0)\n",
    "temp = temp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "id": "f95f4672-45fe-4cde-bb01-f4ed1ef57365",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.drop(columns=fixed_columns)\n",
    "temp = temp.drop(columns=['r_순부채', 'r_EBITDA', 'report_code', '법인유형'], axis=1)\n",
    "temp = temp.reindex(columns=fixed_columns_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1715,
   "id": "669003dc-43a7-41f9-b1ec-43c705776921",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10\n",
    "# threshold = 5\n",
    "temp = temp.drop(index=temp[temp.select_dtypes(include='float64').gt(threshold).any(axis=1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "id": "68c9296a-4ecc-4f32-9b1d-a4c8e0852413",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_columns = ['회사명', 'year', 'report_code', '법인유형']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412af455",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 길이 (3개년치 데이터) -> (2개년치 성장치)\n",
    "seq_length = 2\n",
    "\n",
    "# RNN 입력 데이터로 변환하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for name, group in data.groupby('회사명'):\n",
    "        for i in range(len(group) - seq_length):\n",
    "            sequence = group.iloc[i:i + seq_length].drop(['회사명', 'year'], axis=1).values\n",
    "            target = group.iloc[i + seq_length].drop(['회사명', 'year']).values\n",
    "            sequence = sequence.astype(float)\n",
    "            target = target.astype(float)\n",
    "            sequences.append(sequence)\n",
    "            targets.append(target)\n",
    "    return sequences, targets\n",
    "\n",
    "# RNN 입력 데이터 생성\n",
    "# data, target = create_sequences(f_dart_s4, seq_length)\n",
    "data, target = create_sequences(temp, seq_length)\n",
    "\n",
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "\n",
    "num_companies, num_years, num_features = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc86727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.targets[index], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset(data, target)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "# 데이터 로더를 생성합니다.\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Average Loss: 1.0074\n",
      "Epoch [1/10000], Average Valid Loss: 9.7663\n",
      "Epoch [101/10000], Average Loss: 0.7944\n",
      "Epoch [101/10000], Average Valid Loss: 7.8971\n",
      "Epoch [201/10000], Average Loss: 0.6294\n",
      "Epoch [201/10000], Average Valid Loss: 6.5026\n",
      "Epoch [301/10000], Average Loss: 0.4556\n",
      "Epoch [301/10000], Average Valid Loss: 5.0407\n",
      "Epoch [401/10000], Average Loss: 0.3090\n",
      "Epoch [401/10000], Average Valid Loss: 3.8222\n",
      "Epoch [501/10000], Average Loss: 0.2124\n",
      "Epoch [501/10000], Average Valid Loss: 3.0169\n",
      "Epoch [601/10000], Average Loss: 0.1472\n",
      "Epoch [601/10000], Average Valid Loss: 2.5101\n",
      "Epoch [701/10000], Average Loss: 0.1045\n",
      "Epoch [701/10000], Average Valid Loss: 2.2128\n",
      "Epoch [801/10000], Average Loss: 0.0758\n",
      "Epoch [801/10000], Average Valid Loss: 2.0618\n",
      "Epoch [901/10000], Average Loss: 0.0552\n",
      "Epoch [901/10000], Average Valid Loss: 2.0011\n",
      "Epoch [1001/10000], Average Loss: 0.0407\n",
      "Epoch [1001/10000], Average Valid Loss: 1.9454\n",
      "Epoch [1101/10000], Average Loss: 0.0314\n",
      "Epoch [1101/10000], Average Valid Loss: 1.9232\n",
      "Epoch [1201/10000], Average Loss: 0.0254\n",
      "Epoch [1201/10000], Average Valid Loss: 1.8984\n",
      "Epoch [1301/10000], Average Loss: 0.0207\n",
      "Epoch [1301/10000], Average Valid Loss: 1.8878\n",
      "Epoch [1401/10000], Average Loss: 0.0178\n",
      "Epoch [1401/10000], Average Valid Loss: 1.8754\n",
      "Epoch [1501/10000], Average Loss: 0.0153\n",
      "Epoch [1501/10000], Average Valid Loss: 1.8601\n",
      "Epoch [1601/10000], Average Loss: 0.0135\n",
      "Epoch [1601/10000], Average Valid Loss: 1.8566\n",
      "Epoch [1701/10000], Average Loss: 0.0123\n",
      "Epoch [1701/10000], Average Valid Loss: 1.8709\n",
      "Epoch [1801/10000], Average Loss: 0.0111\n",
      "Epoch [1801/10000], Average Valid Loss: 1.8672\n",
      "Epoch [1901/10000], Average Loss: 0.0104\n",
      "Epoch [1901/10000], Average Valid Loss: 1.8508\n",
      "Epoch [2001/10000], Average Loss: 0.0094\n",
      "Epoch [2001/10000], Average Valid Loss: 1.8634\n",
      "Epoch [2101/10000], Average Loss: 0.0089\n",
      "Epoch [2101/10000], Average Valid Loss: 1.8825\n",
      "Epoch [2201/10000], Average Loss: 0.0084\n",
      "Epoch [2201/10000], Average Valid Loss: 1.8905\n",
      "Epoch [2301/10000], Average Loss: 0.0077\n",
      "Epoch [2301/10000], Average Valid Loss: 1.8926\n",
      "Epoch [2401/10000], Average Loss: 0.0073\n",
      "Epoch [2401/10000], Average Valid Loss: 1.9056\n",
      "Epoch [2501/10000], Average Loss: 0.0067\n",
      "Epoch [2501/10000], Average Valid Loss: 1.9013\n",
      "Epoch [2601/10000], Average Loss: 0.0063\n",
      "Epoch [2601/10000], Average Valid Loss: 1.9249\n",
      "Epoch [2701/10000], Average Loss: 0.0062\n",
      "Epoch [2701/10000], Average Valid Loss: 1.9075\n",
      "Epoch [2801/10000], Average Loss: 0.0057\n",
      "Epoch [2801/10000], Average Valid Loss: 1.9153\n",
      "Epoch [2901/10000], Average Loss: 0.0055\n",
      "Epoch [2901/10000], Average Valid Loss: 1.9353\n",
      "Epoch [3001/10000], Average Loss: 0.0055\n",
      "Epoch [3001/10000], Average Valid Loss: 1.9248\n",
      "Epoch [3101/10000], Average Loss: 0.0050\n",
      "Epoch [3101/10000], Average Valid Loss: 1.9376\n",
      "Epoch [3201/10000], Average Loss: 0.0049\n",
      "Epoch [3201/10000], Average Valid Loss: 1.9411\n",
      "Epoch [3301/10000], Average Loss: 0.0047\n",
      "Epoch [3301/10000], Average Valid Loss: 1.9444\n",
      "Epoch [3401/10000], Average Loss: 0.0047\n",
      "Epoch [3401/10000], Average Valid Loss: 1.9418\n",
      "Epoch [3501/10000], Average Loss: 0.0044\n",
      "Epoch [3501/10000], Average Valid Loss: 1.9300\n",
      "Epoch [3601/10000], Average Loss: 0.0042\n",
      "Epoch [3601/10000], Average Valid Loss: 1.9395\n",
      "Epoch [3701/10000], Average Loss: 0.0042\n",
      "Epoch [3701/10000], Average Valid Loss: 1.9542\n",
      "Epoch [3801/10000], Average Loss: 0.0041\n",
      "Epoch [3801/10000], Average Valid Loss: 1.9546\n",
      "Epoch [3901/10000], Average Loss: 0.0039\n",
      "Epoch [3901/10000], Average Valid Loss: 1.9704\n",
      "Epoch [4001/10000], Average Loss: 0.0038\n",
      "Epoch [4001/10000], Average Valid Loss: 1.9576\n",
      "Epoch [4101/10000], Average Loss: 0.0037\n",
      "Epoch [4101/10000], Average Valid Loss: 1.9499\n",
      "Epoch [4201/10000], Average Loss: 0.0036\n",
      "Epoch [4201/10000], Average Valid Loss: 1.9511\n",
      "Epoch [4301/10000], Average Loss: 0.0033\n",
      "Epoch [4301/10000], Average Valid Loss: 1.9477\n",
      "Epoch [4401/10000], Average Loss: 0.0034\n",
      "Epoch [4401/10000], Average Valid Loss: 1.9666\n",
      "Epoch [4501/10000], Average Loss: 0.0036\n",
      "Epoch [4501/10000], Average Valid Loss: 1.9476\n",
      "Epoch [4601/10000], Average Loss: 0.0032\n",
      "Epoch [4601/10000], Average Valid Loss: 1.9520\n",
      "Epoch [4701/10000], Average Loss: 0.0032\n",
      "Epoch [4701/10000], Average Valid Loss: 1.9374\n",
      "Epoch [4801/10000], Average Loss: 0.0029\n",
      "Epoch [4801/10000], Average Valid Loss: 1.9488\n",
      "Epoch [4901/10000], Average Loss: 0.0030\n",
      "Epoch [4901/10000], Average Valid Loss: 1.9370\n",
      "Epoch [5001/10000], Average Loss: 0.0030\n",
      "Epoch [5001/10000], Average Valid Loss: 1.9419\n",
      "Epoch [5101/10000], Average Loss: 0.0030\n",
      "Epoch [5101/10000], Average Valid Loss: 1.9398\n",
      "Epoch [5201/10000], Average Loss: 0.0028\n",
      "Epoch [5201/10000], Average Valid Loss: 1.9266\n",
      "Epoch [5301/10000], Average Loss: 0.0027\n",
      "Epoch [5301/10000], Average Valid Loss: 1.9424\n",
      "Epoch [5401/10000], Average Loss: 0.0026\n",
      "Epoch [5401/10000], Average Valid Loss: 1.9209\n",
      "Epoch [5501/10000], Average Loss: 0.0026\n",
      "Epoch [5501/10000], Average Valid Loss: 1.9272\n",
      "Epoch [5601/10000], Average Loss: 0.0025\n",
      "Epoch [5601/10000], Average Valid Loss: 1.9150\n",
      "Epoch [5701/10000], Average Loss: 0.0025\n",
      "Epoch [5701/10000], Average Valid Loss: 1.9046\n",
      "Epoch [5801/10000], Average Loss: 0.0024\n",
      "Epoch [5801/10000], Average Valid Loss: 1.9002\n",
      "Epoch [5901/10000], Average Loss: 0.0024\n",
      "Epoch [5901/10000], Average Valid Loss: 1.9146\n",
      "Epoch [6001/10000], Average Loss: 0.0024\n",
      "Epoch [6001/10000], Average Valid Loss: 1.9073\n",
      "Epoch [6101/10000], Average Loss: 0.0024\n",
      "Epoch [6101/10000], Average Valid Loss: 1.9017\n",
      "Epoch [6201/10000], Average Loss: 0.0022\n",
      "Epoch [6201/10000], Average Valid Loss: 1.8969\n",
      "Epoch [6301/10000], Average Loss: 0.0023\n",
      "Epoch [6301/10000], Average Valid Loss: 1.8927\n",
      "Epoch [6401/10000], Average Loss: 0.0023\n",
      "Epoch [6401/10000], Average Valid Loss: 1.8849\n",
      "Epoch [6501/10000], Average Loss: 0.0024\n",
      "Epoch [6501/10000], Average Valid Loss: 1.8840\n",
      "Epoch [6601/10000], Average Loss: 0.0022\n",
      "Epoch [6601/10000], Average Valid Loss: 1.8799\n",
      "Epoch [6701/10000], Average Loss: 0.0021\n",
      "Epoch [6701/10000], Average Valid Loss: 1.8759\n",
      "Epoch [6801/10000], Average Loss: 0.0021\n",
      "Epoch [6801/10000], Average Valid Loss: 1.8722\n",
      "Epoch [6901/10000], Average Loss: 0.0021\n",
      "Epoch [6901/10000], Average Valid Loss: 1.8685\n",
      "Epoch [7001/10000], Average Loss: 0.0019\n",
      "Epoch [7001/10000], Average Valid Loss: 1.8681\n",
      "Epoch [7101/10000], Average Loss: 0.0020\n",
      "Epoch [7101/10000], Average Valid Loss: 1.8520\n",
      "Epoch [7201/10000], Average Loss: 0.0018\n",
      "Epoch [7201/10000], Average Valid Loss: 1.8556\n",
      "Epoch [7301/10000], Average Loss: 0.0020\n",
      "Epoch [7301/10000], Average Valid Loss: 1.8540\n",
      "Epoch [7401/10000], Average Loss: 0.0019\n",
      "Epoch [7401/10000], Average Valid Loss: 1.8372\n",
      "Epoch [7501/10000], Average Loss: 0.0019\n",
      "Epoch [7501/10000], Average Valid Loss: 1.8338\n",
      "Epoch [7601/10000], Average Loss: 0.0018\n",
      "Epoch [7601/10000], Average Valid Loss: 1.8438\n",
      "Epoch [7701/10000], Average Loss: 0.0018\n",
      "Epoch [7701/10000], Average Valid Loss: 1.8321\n",
      "Epoch [7801/10000], Average Loss: 0.0017\n",
      "Epoch [7801/10000], Average Valid Loss: 1.8283\n",
      "Epoch [7901/10000], Average Loss: 0.0018\n",
      "Epoch [7901/10000], Average Valid Loss: 1.8251\n",
      "Epoch [8001/10000], Average Loss: 0.0019\n",
      "Epoch [8001/10000], Average Valid Loss: 1.8244\n",
      "Epoch [8101/10000], Average Loss: 0.0017\n",
      "Epoch [8101/10000], Average Valid Loss: 1.8176\n",
      "Epoch [8201/10000], Average Loss: 0.0017\n",
      "Epoch [8201/10000], Average Valid Loss: 1.8135\n",
      "Epoch [8301/10000], Average Loss: 0.0018\n",
      "Epoch [8301/10000], Average Valid Loss: 1.8087\n",
      "Epoch [8401/10000], Average Loss: 0.0017\n",
      "Epoch [8401/10000], Average Valid Loss: 1.7995\n",
      "Epoch [8501/10000], Average Loss: 0.0016\n",
      "Epoch [8501/10000], Average Valid Loss: 1.7991\n",
      "Epoch [8601/10000], Average Loss: 0.0016\n",
      "Epoch [8601/10000], Average Valid Loss: 1.7953\n",
      "Epoch [8701/10000], Average Loss: 0.0016\n",
      "Epoch [8701/10000], Average Valid Loss: 1.7936\n",
      "Epoch [8801/10000], Average Loss: 0.0016\n",
      "Epoch [8801/10000], Average Valid Loss: 1.7857\n",
      "Epoch [8901/10000], Average Loss: 0.0016\n",
      "Epoch [8901/10000], Average Valid Loss: 1.7856\n",
      "Epoch [9001/10000], Average Loss: 0.0015\n",
      "Epoch [9001/10000], Average Valid Loss: 1.7856\n",
      "Epoch [9101/10000], Average Loss: 0.0015\n",
      "Epoch [9101/10000], Average Valid Loss: 1.7884\n",
      "Epoch [9201/10000], Average Loss: 0.0015\n",
      "Epoch [9201/10000], Average Valid Loss: 1.7712\n",
      "Epoch [9301/10000], Average Loss: 0.0015\n",
      "Epoch [9301/10000], Average Valid Loss: 1.7620\n",
      "Epoch [9401/10000], Average Loss: 0.0014\n",
      "Epoch [9401/10000], Average Valid Loss: 1.7637\n",
      "Epoch [9501/10000], Average Loss: 0.0015\n",
      "Epoch [9501/10000], Average Valid Loss: 1.7646\n",
      "Epoch [9601/10000], Average Loss: 0.0015\n",
      "Epoch [9601/10000], Average Valid Loss: 1.7592\n",
      "Epoch [9701/10000], Average Loss: 0.0015\n",
      "Epoch [9701/10000], Average Valid Loss: 1.7559\n",
      "Epoch [9801/10000], Average Loss: 0.0014\n",
      "Epoch [9801/10000], Average Valid Loss: 1.7543\n",
      "Epoch [9901/10000], Average Loss: 0.0015\n",
      "Epoch [9901/10000], Average Valid Loss: 1.7456\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "input_size = num_features\n",
    "hidden_size = 16\n",
    "output_size = num_features\n",
    "\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# 손실 함수 및 최적화 함수\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10000\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    avg_v_loss = total_loss / len(valid_loader)\n",
    "    \n",
    "    if epoch % 100 == 0: \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Valid Loss: {avg_v_loss:.4f}\")\n",
    "    \n",
    "    if avg_v_loss < best_loss:\n",
    "        best_loss = avg_v_loss\n",
    "\n",
    "        # 모델과 optimizer의 상태를 저장합니다.\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }\n",
    "        torch.save(checkpoint, './checkpoint_rnn_2.pth')\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = smes_company_r.groupby(['회사명']).size()\n",
    "smes_company_r_filter = smes_company_r[smes_company_r['회사명'].isin(gs[gs==2].index)]\n",
    "smes_company_r_filter = smes_company_r_filter.sort_values(['회사명', 'year'])\n",
    "smes_company_r_filter = smes_company_r_filter.drop(['EBITDA배율'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "seq_length = 2\n",
    "output_list = list()\n",
    "\n",
    "model.eval()\n",
    "for name, group in smes_company_r_filter.groupby('회사명'):\n",
    "    # for i in range(len(group) - seq_length):\n",
    "    with torch.no_grad():\n",
    "        corp_name = group.iloc[0]['회사명']\n",
    "        corp_year = group.iloc[0]['year'] + 2\n",
    "        inputs = torch.tensor(group.iloc[0:0+seq_length].drop(['회사명', 'year'], axis=1).values, dtype=torch.float32)\n",
    "        inputs = torch.reshape(inputs, (1, inputs.size(0), inputs.size(1)))\n",
    "        outputs = model(inputs)\n",
    "        output_list.append([corp_name, corp_year, outputs.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = pd.DataFrame(output_list)\n",
    "final_output = pd.concat([test_output.loc[:,:1], pd.DataFrame([value for value in test_output[2].apply(np.squeeze).values])], axis = 1)\n",
    "final_output.columns = temp.columns\n",
    "final_output = pd.merge(final_output, smes_company, on=['회사명', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a288f-539a-4eac-bcdd-c89221024cd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "id": "d5ff77f2-c7a7-4d7c-813e-9ec191f5ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "id": "cad8650c-949e-419d-b7a1-b17e293332d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "id": "8f0b873e-c717-4854-b462-dbf9abee4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 길이 (3개년치 데이터)\n",
    "# seq_length = 3\n",
    "seq_length = 2\n",
    "\n",
    "# LSTM 입력 데이터로 변환하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for name, group in data.groupby('회사명'):\n",
    "        for i in range(len(group) - seq_length):\n",
    "            sequence = group.iloc[i:i + seq_length].drop(['회사명', 'year'], axis=1).values\n",
    "            target = group.iloc[i + seq_length].drop(['회사명', 'year']).values\n",
    "            sequence = sequence.astype(float)\n",
    "            target = target.astype(float)\n",
    "            sequences.append(sequence)\n",
    "            targets.append(target)\n",
    "    return sequences, targets\n",
    "\n",
    "# LSTM 입력 데이터 생성\n",
    "# data, target = create_sequences(f_dart_s4, seq_length)\n",
    "data, target = create_sequences(temp, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "973b3c5a-6424-454d-9985-1e18992d95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "\n",
    "num_companies, num_years, num_features = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "id": "cd977667-4359-48c0-813e-54365d223e67",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data_reshaped = data.reshape((num_companies * num_years, num_features))\n",
    "\n",
    "scalers = {}\n",
    "for i in range(num_features):\n",
    "    # feature_scaler = MinMaxScaler()\n",
    "    feature_scaler = RobustScaler()\n",
    "    data_reshaped[:, i] = feature_scaler.fit_transform(data_reshaped[:, i].reshape(-1, 1)).flatten()\n",
    "    scalers[i] = feature_scaler\n",
    "\n",
    "# 데이터의 차원을 다시 (3136, 3, 10)으로 복원합니다.\n",
    "data_scaled = data_reshaped.reshape((num_companies, num_years, num_features))\n",
    "\n",
    "# 타겟 데이터를 스케일링합니다.\n",
    "# target_scaler = MinMaxScaler()\n",
    "target_scaler = RobustScaler()\n",
    "target_scaled = target_scaler.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1720,
   "id": "5f34942f-dadd-4493-a8d5-79358483e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.targets[index], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset(data, target)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "id": "80812c5d-2f84-4184-8fd2-c6f5aa9e259a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Average Loss: 1.0786\n",
      "Epoch [1/10000], Average Valid Loss: 9.9747\n",
      "Epoch [101/10000], Average Loss: 0.9038\n",
      "Epoch [101/10000], Average Valid Loss: 8.4113\n",
      "Epoch [201/10000], Average Loss: 0.8562\n",
      "Epoch [201/10000], Average Valid Loss: 8.0034\n",
      "Epoch [301/10000], Average Loss: 0.8194\n",
      "Epoch [301/10000], Average Valid Loss: 7.7002\n",
      "Epoch [401/10000], Average Loss: 0.7970\n",
      "Epoch [401/10000], Average Valid Loss: 7.5212\n",
      "Epoch [501/10000], Average Loss: 0.7752\n",
      "Epoch [501/10000], Average Valid Loss: 7.3477\n",
      "Epoch [601/10000], Average Loss: 0.7533\n",
      "Epoch [601/10000], Average Valid Loss: 7.1729\n",
      "Epoch [701/10000], Average Loss: 0.7450\n",
      "Epoch [701/10000], Average Valid Loss: 7.1133\n",
      "Epoch [801/10000], Average Loss: 0.7221\n",
      "Epoch [801/10000], Average Valid Loss: 6.9309\n",
      "Epoch [901/10000], Average Loss: 0.7076\n",
      "Epoch [901/10000], Average Valid Loss: 6.8195\n",
      "Epoch [1001/10000], Average Loss: 0.6914\n",
      "Epoch [1001/10000], Average Valid Loss: 6.6947\n",
      "Epoch [1101/10000], Average Loss: 0.6875\n",
      "Epoch [1101/10000], Average Valid Loss: 6.6713\n",
      "Epoch [1201/10000], Average Loss: 0.6634\n",
      "Epoch [1201/10000], Average Valid Loss: 6.4781\n",
      "Epoch [1301/10000], Average Loss: 0.6488\n",
      "Epoch [1301/10000], Average Valid Loss: 6.3639\n",
      "Epoch [1401/10000], Average Loss: 0.6332\n",
      "Epoch [1401/10000], Average Valid Loss: 6.2411\n",
      "Epoch [1501/10000], Average Loss: 0.6191\n",
      "Epoch [1501/10000], Average Valid Loss: 6.1300\n",
      "Epoch [1601/10000], Average Loss: 0.6048\n",
      "Epoch [1601/10000], Average Valid Loss: 6.0172\n",
      "Epoch [1701/10000], Average Loss: 0.5932\n",
      "Epoch [1701/10000], Average Valid Loss: 5.9259\n",
      "Epoch [1801/10000], Average Loss: 0.5825\n",
      "Epoch [1801/10000], Average Valid Loss: 5.8454\n",
      "Epoch [1901/10000], Average Loss: 0.5736\n",
      "Epoch [1901/10000], Average Valid Loss: 5.7789\n",
      "Epoch [2001/10000], Average Loss: 0.5596\n",
      "Epoch [2001/10000], Average Valid Loss: 5.6705\n",
      "Epoch [2101/10000], Average Loss: 0.5534\n",
      "Epoch [2101/10000], Average Valid Loss: 5.6283\n",
      "Epoch [2201/10000], Average Loss: 0.5397\n",
      "Epoch [2201/10000], Average Valid Loss: 5.5241\n",
      "Epoch [2301/10000], Average Loss: 0.5305\n",
      "Epoch [2301/10000], Average Valid Loss: 5.4603\n",
      "Epoch [2401/10000], Average Loss: 0.5216\n",
      "Epoch [2401/10000], Average Valid Loss: 5.3965\n",
      "Epoch [2501/10000], Average Loss: 0.5169\n",
      "Epoch [2501/10000], Average Valid Loss: 5.3709\n",
      "Epoch [2601/10000], Average Loss: 0.5069\n",
      "Epoch [2601/10000], Average Valid Loss: 5.3014\n",
      "Epoch [2701/10000], Average Loss: 0.4992\n",
      "Epoch [2701/10000], Average Valid Loss: 5.2507\n",
      "Epoch [2801/10000], Average Loss: 0.4906\n",
      "Epoch [2801/10000], Average Valid Loss: 5.1904\n",
      "Epoch [2901/10000], Average Loss: 0.4861\n",
      "Epoch [2901/10000], Average Valid Loss: 5.1651\n",
      "Epoch [3001/10000], Average Loss: 0.4792\n",
      "Epoch [3001/10000], Average Valid Loss: 5.1198\n",
      "Epoch [3101/10000], Average Loss: 0.4701\n",
      "Epoch [3101/10000], Average Valid Loss: 5.0563\n",
      "Epoch [3201/10000], Average Loss: 0.4638\n",
      "Epoch [3201/10000], Average Valid Loss: 5.0152\n",
      "Epoch [3301/10000], Average Loss: 0.4634\n",
      "Epoch [3301/10000], Average Valid Loss: 5.0243\n",
      "Epoch [3401/10000], Average Loss: 0.4561\n",
      "Epoch [3401/10000], Average Valid Loss: 4.9737\n",
      "Epoch [3501/10000], Average Loss: 0.4498\n",
      "Epoch [3501/10000], Average Valid Loss: 4.9317\n",
      "Epoch [3601/10000], Average Loss: 0.4438\n",
      "Epoch [3601/10000], Average Valid Loss: 4.8929\n",
      "Epoch [3701/10000], Average Loss: 0.4375\n",
      "Epoch [3701/10000], Average Valid Loss: 4.8500\n",
      "Epoch [3801/10000], Average Loss: 0.4321\n",
      "Epoch [3801/10000], Average Valid Loss: 4.8147\n",
      "Epoch [3901/10000], Average Loss: 0.4290\n",
      "Epoch [3901/10000], Average Valid Loss: 4.7979\n",
      "Epoch [4001/10000], Average Loss: 0.4246\n",
      "Epoch [4001/10000], Average Valid Loss: 4.7699\n",
      "Epoch [4101/10000], Average Loss: 0.4187\n",
      "Epoch [4101/10000], Average Valid Loss: 4.7284\n",
      "Epoch [4201/10000], Average Loss: 0.4148\n",
      "Epoch [4201/10000], Average Valid Loss: 4.7040\n",
      "Epoch [4301/10000], Average Loss: 0.4111\n",
      "Epoch [4301/10000], Average Valid Loss: 4.6809\n",
      "Epoch [4401/10000], Average Loss: 0.4070\n",
      "Epoch [4401/10000], Average Valid Loss: 4.6539\n",
      "Epoch [4501/10000], Average Loss: 0.4029\n",
      "Epoch [4501/10000], Average Valid Loss: 4.6257\n",
      "Epoch [4601/10000], Average Loss: 0.3985\n",
      "Epoch [4601/10000], Average Valid Loss: 4.5969\n",
      "Epoch [4701/10000], Average Loss: 0.3961\n",
      "Epoch [4701/10000], Average Valid Loss: 4.5834\n",
      "Epoch [4801/10000], Average Loss: 0.3926\n",
      "Epoch [4801/10000], Average Valid Loss: 4.5608\n",
      "Epoch [4901/10000], Average Loss: 0.3873\n",
      "Epoch [4901/10000], Average Valid Loss: 4.5234\n",
      "Epoch [5001/10000], Average Loss: 0.3874\n",
      "Epoch [5001/10000], Average Valid Loss: 4.5301\n",
      "Epoch [5101/10000], Average Loss: 0.3810\n",
      "Epoch [5101/10000], Average Valid Loss: 4.4836\n",
      "Epoch [5201/10000], Average Loss: 0.3789\n",
      "Epoch [5201/10000], Average Valid Loss: 4.4735\n",
      "Epoch [5301/10000], Average Loss: 0.3743\n",
      "Epoch [5301/10000], Average Valid Loss: 4.4422\n",
      "Epoch [5401/10000], Average Loss: 0.3738\n",
      "Epoch [5401/10000], Average Valid Loss: 4.4447\n",
      "Epoch [5501/10000], Average Loss: 0.3684\n",
      "Epoch [5501/10000], Average Valid Loss: 4.4078\n",
      "Epoch [5601/10000], Average Loss: 0.3650\n",
      "Epoch [5601/10000], Average Valid Loss: 4.3850\n",
      "Epoch [5701/10000], Average Loss: 0.3687\n",
      "Epoch [5701/10000], Average Valid Loss: 4.4235\n",
      "Epoch [5801/10000], Average Loss: 0.3641\n",
      "Epoch [5801/10000], Average Valid Loss: 4.3927\n",
      "Epoch [5901/10000], Average Loss: 0.3617\n",
      "Epoch [5901/10000], Average Valid Loss: 4.3801\n",
      "Epoch [6001/10000], Average Loss: 0.3549\n",
      "Epoch [6001/10000], Average Valid Loss: 4.3309\n",
      "Epoch [6101/10000], Average Loss: 0.3515\n",
      "Epoch [6101/10000], Average Valid Loss: 4.3098\n",
      "Epoch [6201/10000], Average Loss: 0.3481\n",
      "Epoch [6201/10000], Average Valid Loss: 4.2890\n",
      "Epoch [6301/10000], Average Loss: 0.3456\n",
      "Epoch [6301/10000], Average Valid Loss: 4.2744\n",
      "Epoch [6401/10000], Average Loss: 0.3431\n",
      "Epoch [6401/10000], Average Valid Loss: 4.2597\n",
      "Epoch [6501/10000], Average Loss: 0.3444\n",
      "Epoch [6501/10000], Average Valid Loss: 4.2753\n",
      "Epoch [6601/10000], Average Loss: 0.3396\n",
      "Epoch [6601/10000], Average Valid Loss: 4.2402\n",
      "Epoch [6701/10000], Average Loss: 0.3381\n",
      "Epoch [6701/10000], Average Valid Loss: 4.2329\n",
      "Epoch [6801/10000], Average Loss: 0.3359\n",
      "Epoch [6801/10000], Average Valid Loss: 4.2203\n",
      "Epoch [6901/10000], Average Loss: 0.3310\n",
      "Epoch [6901/10000], Average Valid Loss: 4.1842\n",
      "Epoch [7001/10000], Average Loss: 0.3295\n",
      "Epoch [7001/10000], Average Valid Loss: 4.1779\n",
      "Epoch [7101/10000], Average Loss: 0.3287\n",
      "Epoch [7101/10000], Average Valid Loss: 4.1769\n",
      "Epoch [7201/10000], Average Loss: 0.3284\n",
      "Epoch [7201/10000], Average Valid Loss: 4.1795\n",
      "Epoch [7301/10000], Average Loss: 0.3249\n",
      "Epoch [7301/10000], Average Valid Loss: 4.1557\n",
      "Epoch [7401/10000], Average Loss: 0.3213\n",
      "Epoch [7401/10000], Average Valid Loss: 4.1301\n",
      "Epoch [7501/10000], Average Loss: 0.3207\n",
      "Epoch [7501/10000], Average Valid Loss: 4.1311\n",
      "Epoch [7601/10000], Average Loss: 0.3190\n",
      "Epoch [7601/10000], Average Valid Loss: 4.1231\n",
      "Epoch [7701/10000], Average Loss: 0.3174\n",
      "Epoch [7701/10000], Average Valid Loss: 4.1154\n",
      "Epoch [7801/10000], Average Loss: 0.3154\n",
      "Epoch [7801/10000], Average Valid Loss: 4.1043\n",
      "Epoch [7901/10000], Average Loss: 0.3140\n",
      "Epoch [7901/10000], Average Valid Loss: 4.0985\n",
      "Epoch [8001/10000], Average Loss: 0.3109\n",
      "Epoch [8001/10000], Average Valid Loss: 4.0785\n",
      "Epoch [8101/10000], Average Loss: 0.3100\n",
      "Epoch [8101/10000], Average Valid Loss: 4.0780\n",
      "Epoch [8201/10000], Average Loss: 0.3079\n",
      "Epoch [8201/10000], Average Valid Loss: 4.0669\n",
      "Epoch [8301/10000], Average Loss: 0.3061\n",
      "Epoch [8301/10000], Average Valid Loss: 4.0571\n",
      "Epoch [8401/10000], Average Loss: 0.3058\n",
      "Epoch [8401/10000], Average Valid Loss: 4.0614\n",
      "Epoch [8501/10000], Average Loss: 0.3039\n",
      "Epoch [8501/10000], Average Valid Loss: 4.0514\n",
      "Epoch [8601/10000], Average Loss: 0.3032\n",
      "Epoch [8601/10000], Average Valid Loss: 4.0528\n",
      "Epoch [8701/10000], Average Loss: 0.3024\n",
      "Epoch [8701/10000], Average Valid Loss: 4.0492\n",
      "Epoch [8801/10000], Average Loss: 0.3028\n",
      "Epoch [8801/10000], Average Valid Loss: 4.0597\n",
      "Epoch [8901/10000], Average Loss: 0.2989\n",
      "Epoch [8901/10000], Average Valid Loss: 4.0323\n",
      "Epoch [9001/10000], Average Loss: 0.2969\n",
      "Epoch [9001/10000], Average Valid Loss: 4.0227\n",
      "Epoch [9101/10000], Average Loss: 0.2953\n",
      "Epoch [9101/10000], Average Valid Loss: 4.0137\n",
      "Epoch [9201/10000], Average Loss: 0.2941\n",
      "Epoch [9201/10000], Average Valid Loss: 4.0108\n",
      "Epoch [9301/10000], Average Loss: 0.2982\n",
      "Epoch [9301/10000], Average Valid Loss: 4.0503\n",
      "Epoch [9401/10000], Average Loss: 0.2925\n",
      "Epoch [9401/10000], Average Valid Loss: 4.0073\n",
      "Epoch [9501/10000], Average Loss: 0.2916\n",
      "Epoch [9501/10000], Average Valid Loss: 4.0051\n",
      "Epoch [9601/10000], Average Loss: 0.2888\n",
      "Epoch [9601/10000], Average Valid Loss: 3.9866\n",
      "Epoch [9701/10000], Average Loss: 0.2879\n",
      "Epoch [9701/10000], Average Valid Loss: 3.9845\n",
      "Epoch [9801/10000], Average Loss: 0.2881\n",
      "Epoch [9801/10000], Average Valid Loss: 3.9921\n",
      "Epoch [9901/10000], Average Loss: 0.2857\n",
      "Epoch [9901/10000], Average Valid Loss: 3.9770\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "input_size = num_features\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "output_size = num_features\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# 손실 함수 및 최적화 함수\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10000\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    avg_v_loss = total_loss / len(valid_loader)\n",
    "    \n",
    "    if epoch % 100 == 0: \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Valid Loss: {avg_v_loss:.4f}\")\n",
    "    \n",
    "    if avg_v_loss < best_loss:\n",
    "        best_loss = avg_v_loss\n",
    "\n",
    "        # 모델과 optimizer의 상태를 저장합니다.\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }\n",
    "        torch.save(checkpoint, './checkpoint_4.pth')\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "id": "73ad1552-02cd-4753-9923-ccc6484d5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = smes_company_r.groupby(['회사명']).size()\n",
    "smes_company_r_filter = smes_company_r[smes_company_r['회사명'].isin(gs[gs==2].index)]\n",
    "smes_company_r_filter = smes_company_r_filter.sort_values(['회사명', 'year'])\n",
    "smes_company_r_filter = smes_company_r_filter.drop(['EBITDA배율'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "f0ba7674-9290-4231-b7bc-fbd85d225c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "seq_length = 2\n",
    "output_list = list()\n",
    "\n",
    "model.eval()\n",
    "for name, group in smes_company_r_filter.groupby('회사명'):\n",
    "    # for i in range(len(group) - seq_length):\n",
    "    with torch.no_grad():\n",
    "        corp_name = group.iloc[0]['회사명']\n",
    "        corp_year = group.iloc[0]['year'] + 2\n",
    "        inputs = torch.tensor(group.iloc[0:0+seq_length].drop(['회사명', 'year'], axis=1).values, dtype=torch.float32)\n",
    "        inputs = torch.reshape(inputs, (1, inputs.size(0), inputs.size(1)))\n",
    "        outputs = model(inputs)\n",
    "        output_list.append([corp_name, corp_year, outputs.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "id": "a7683572-88fa-49cf-bac2-32cb8f6be16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = pd.DataFrame(output_list)\n",
    "final_output = pd.concat([test_output.loc[:,:1], pd.DataFrame([value for value in test_output[2].apply(np.squeeze).values])], axis = 1)\n",
    "final_output.columns = temp.columns\n",
    "final_output = pd.merge(final_output, smes_company, on=['회사명', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333db93",
   "metadata": {},
   "source": [
    "# Rule base\n",
    "- 최종 DCF 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "id": "3ebfa4ad-0642-43d6-9f95-16a533677382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fcolumns = ['부채총계', '자본총계', '매출액', '당기순이익', '영업이익', '현금및현금성자산', '감가상각비']\n",
    "for t in fcolumns:\n",
    "    final_output[f'p_{t}'] = final_output[f'r_{t}'] * final_output[t]\n",
    "final_output['p_EBITDA'] = final_output['p_영업이익'] + final_output['p_감가상각비']\n",
    "\n",
    "conditions = [\n",
    "    (final_output['p_매출액'] <= 2e+8),\n",
    "    (final_output['p_매출액'] > 2e+8) & (final_output['p_매출액'] <= 2e+10),\n",
    "    (final_output['p_매출액'] > 2e+10) & (final_output['p_매출액'] <= 3e+11),\n",
    "    (final_output['p_매출액'] > 3e+11)\n",
    "]\n",
    "values = [0.09, 0.19, 0.21, 0.24]\n",
    "\n",
    "final_output['p_법인세율'] = np.select(conditions, values, default='Other')\n",
    "final_output['p_영업이익_t'] = final_output['p_영업이익'] * (1 - final_output['p_법인세율'].apply(float))\n",
    "final_output['p_현금흐름'] = (final_output['p_영업이익_t'] + final_output['p_감가상각비']) * final_output['EBITDA배율']\n",
    "p_output = final_output[['회사명', 'p_현금흐름']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "id": "e27452c1-e016-421c-a473-b1bc5afb2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smes_capm = pd.read_csv('./smes_capm_filtered_iqr.csv')\n",
    "smes_capm = smes_capm[['회사명', 'CAPM']]\n",
    "smes_capm = smes_capm.drop_duplicates('회사명')\n",
    "smes_capm = pd.merge(smes_capm, p_output, on='회사명')\n",
    "smes_capm['기업 가치'] = smes_capm['p_현금흐름'] / smes_capm['CAPM']\n",
    "smes_capm[['회사명', '기업 가치']].to_csv('./8_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
